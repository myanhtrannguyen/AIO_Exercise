{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "1. Import libraries"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "91586cc2ab5f15c8"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/trannguyenmyanh/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/trannguyenmyanh/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "import string \n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-10T05:41:26.708999Z",
     "start_time": "2024-08-10T05:39:23.564252Z"
    }
   },
   "id": "640c0fc18e091507",
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "2. Reading Data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cea6da893ef44699"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/content/2cls_spam_text_cls.csv'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m DATASET_PATH \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m/content/2cls_spam_text_cls.csv\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m----> 2\u001B[0m df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_csv(DATASET_PATH)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:912\u001B[0m, in \u001B[0;36mread_csv\u001B[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001B[0m\n\u001B[1;32m    899\u001B[0m kwds_defaults \u001B[38;5;241m=\u001B[39m _refine_defaults_read(\n\u001B[1;32m    900\u001B[0m     dialect,\n\u001B[1;32m    901\u001B[0m     delimiter,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    908\u001B[0m     dtype_backend\u001B[38;5;241m=\u001B[39mdtype_backend,\n\u001B[1;32m    909\u001B[0m )\n\u001B[1;32m    910\u001B[0m kwds\u001B[38;5;241m.\u001B[39mupdate(kwds_defaults)\n\u001B[0;32m--> 912\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:577\u001B[0m, in \u001B[0;36m_read\u001B[0;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[1;32m    574\u001B[0m _validate_names(kwds\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnames\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m))\n\u001B[1;32m    576\u001B[0m \u001B[38;5;66;03m# Create the parser.\u001B[39;00m\n\u001B[0;32m--> 577\u001B[0m parser \u001B[38;5;241m=\u001B[39m TextFileReader(filepath_or_buffer, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[1;32m    579\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m chunksize \u001B[38;5;129;01mor\u001B[39;00m iterator:\n\u001B[1;32m    580\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1407\u001B[0m, in \u001B[0;36mTextFileReader.__init__\u001B[0;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[1;32m   1404\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m kwds[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m   1406\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles: IOHandles \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m-> 1407\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_make_engine(f, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mengine)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1661\u001B[0m, in \u001B[0;36mTextFileReader._make_engine\u001B[0;34m(self, f, engine)\u001B[0m\n\u001B[1;32m   1659\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m mode:\n\u001B[1;32m   1660\u001B[0m         mode \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m-> 1661\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;241m=\u001B[39m get_handle(\n\u001B[1;32m   1662\u001B[0m     f,\n\u001B[1;32m   1663\u001B[0m     mode,\n\u001B[1;32m   1664\u001B[0m     encoding\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mencoding\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m),\n\u001B[1;32m   1665\u001B[0m     compression\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcompression\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m),\n\u001B[1;32m   1666\u001B[0m     memory_map\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmemory_map\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m),\n\u001B[1;32m   1667\u001B[0m     is_text\u001B[38;5;241m=\u001B[39mis_text,\n\u001B[1;32m   1668\u001B[0m     errors\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mencoding_errors\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstrict\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[1;32m   1669\u001B[0m     storage_options\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstorage_options\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m),\n\u001B[1;32m   1670\u001B[0m )\n\u001B[1;32m   1671\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1672\u001B[0m f \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles\u001B[38;5;241m.\u001B[39mhandle\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/common.py:859\u001B[0m, in \u001B[0;36mget_handle\u001B[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[1;32m    854\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(handle, \u001B[38;5;28mstr\u001B[39m):\n\u001B[1;32m    855\u001B[0m     \u001B[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001B[39;00m\n\u001B[1;32m    856\u001B[0m     \u001B[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001B[39;00m\n\u001B[1;32m    857\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mencoding \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mmode:\n\u001B[1;32m    858\u001B[0m         \u001B[38;5;66;03m# Encoding\u001B[39;00m\n\u001B[0;32m--> 859\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(\n\u001B[1;32m    860\u001B[0m             handle,\n\u001B[1;32m    861\u001B[0m             ioargs\u001B[38;5;241m.\u001B[39mmode,\n\u001B[1;32m    862\u001B[0m             encoding\u001B[38;5;241m=\u001B[39mioargs\u001B[38;5;241m.\u001B[39mencoding,\n\u001B[1;32m    863\u001B[0m             errors\u001B[38;5;241m=\u001B[39merrors,\n\u001B[1;32m    864\u001B[0m             newline\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    865\u001B[0m         )\n\u001B[1;32m    866\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    867\u001B[0m         \u001B[38;5;66;03m# Binary mode\u001B[39;00m\n\u001B[1;32m    868\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(handle, ioargs\u001B[38;5;241m.\u001B[39mmode)\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '/content/2cls_spam_text_cls.csv'"
     ]
    }
   ],
   "source": [
    "DATASET_PATH = '/content/2cls_spam_text_cls.csv'\n",
    "df = pd.read_csv(DATASET_PATH)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-10T05:44:24.591586Z",
     "start_time": "2024-08-10T05:44:24.528432Z"
    }
   },
   "id": "f66629dd3183df6d",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "messages = df['Message'].values.tolist()\n",
    "labels = df['Category'].values.tolist()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9c8cf1e96cd6c31d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "3. Data Preprocessing "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e46ebee1bbfa55e1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "3.1. Data Preprocessing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a69880fe9c81e8e9"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y = le.fit_transform(labels)\n",
    "print(f'Classes: {le.classes_}')\n",
    "print(f'Encoded labels: {y}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "60145b1da4712e7f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "3.2. Data Preprocessing Mail Content"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cd57234d280ef132"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def lowercase(text):\n",
    "    return text.lower()\n",
    "def punctuation_removal(text):\n",
    "    translator = str.maketrans('', '', string.punctuation) \n",
    "    return text.translate(translator)\n",
    "def tokenize(text):\n",
    "    return nltk.word_tokenize(text)\n",
    "def remove_stopwords(text):\n",
    "    stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "    return [word for word in text if word not in stop_words]\n",
    "def stemming(tokens):\n",
    "    stemmer = nltk.PorterStemmer()\n",
    "    return [stemmer.stem(token) for token in tokens]\n",
    "def preprocess_text(text):\n",
    "    text = lowercase(text)\n",
    "    text = punctuation_removal(text)\n",
    "    tokens = tokenize(text)\n",
    "    tokens = remove_stopwords(tokens)\n",
    "    tokens = stemming(tokens)\n",
    "    return tokens"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f8822e7053d864f1"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "messages = [preprocess_text(message) for message in messages]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "feeb3d5b738133b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "3.3. Build vocab"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dd034a2108aaa9eb"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def create_dictionary(messages):\n",
    "    dictionary = []\n",
    "    for tokens in messages:\n",
    "        for token in tokens:\n",
    "            if token not in dictionary:\n",
    "                dictionary.append(token)\n",
    "    return dictionary\n",
    "dictionary = create_dictionary(messages)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4a5584ae50bb5886"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def create_feature(tokens, dictionary):\n",
    "    features = np.zeros(len(dictionary))\n",
    "    for token in tokens:\n",
    "        if token in dictionary:\n",
    "            features[dictionary.index(token)] += 1\n",
    "    return features\n",
    "dictionary = create_dictionary(messages)\n",
    "X = np.array([create_feature(tokens, dictionary) for tokens in messages])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1d4c36384fd0b90e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "3.4. Coding step: Label Encoding"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fd0f5e4389c6df10"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "VAL_SIZE = 0.2\n",
    "TEST_SIZE = 0.125\n",
    "SEED = 0\n",
    "IS_SHUFFLE = True\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y,\n",
    "    test_size = VAL_SIZE,\n",
    "    shuffle = IS_SHUFFLE,\n",
    "    random_state = SEED\n",
    ")\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_train, y_train,\n",
    "    test_size = TEST_SIZE,\n",
    "    shuffle = IS_SHUFFLE,\n",
    "    random_state = SEED\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cb96fcefeb1b9407"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(f'Number of training samples: {X_train.shape[0]}')\n",
    "print(f'Number of validation samples: {X_val.shape[0]}')\n",
    "print(f'Number of testing samples: {X_test.shape[0]}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "568a40110fbb15e9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "4. Training model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e4aa6f29c5daec1d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "%%time\n",
    "model = GaussianNB()\n",
    "print('Start training...')\n",
    "model = model.fit(X_train, y_train)\n",
    "print('Training completed!')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4bfce0f4944968d6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "5. Evaluate model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "edd2e27fb3eae9cb"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "y_val_pred = model.predict(X_val)\n",
    "y_test_pred = model.predict(X_test)\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(f'Val accuracy: {val_accuracy}')\n",
    "print(f'Test accuracy: {test_accuracy}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "44f7c42ecf307cfe"
  },
  {
   "cell_type": "markdown",
   "source": [
    "6. Predict"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "16668c5c83d2b0ab"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def predict(text, model, dictionary):\n",
    "    processed_text = preprocess_text(text)\n",
    "    features = create_features(text, dictionary)\n",
    "    features = np.array(features).reshape(1, -1)\n",
    "    prediction = model.predict(features)\n",
    "    prediction_cls = le.inverse_transform(prediction)[0]\n",
    "\n",
    "    return prediction_cls"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eea403668af75889"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "test_input = 'I am actually thinking a way of doing something useful'\n",
    "prediction_cls = predict(test_input, model, dictionary)\n",
    "print(f'Prediction: {prediction_cls}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6c04c63651d9ec89"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
